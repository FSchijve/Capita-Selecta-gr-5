{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "applied-abortion",
   "metadata": {},
   "source": [
    "# Pytorch try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adopted-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path \n",
    "import os\n",
    "\n",
    "data_path = (r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\TrainingData')\n",
    "elastix_path = os.path.join(r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\elastix-5.0.1-win64\\elastix.exe')\n",
    "transformix_path = os.path.join(r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\elastix-5.0.1-win64\\transformix.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intellectual-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in c:\\users\\darja\\anaconda3\\envs\\part2_8md20\\lib\\site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "# First, we import PyTorch and NumPy\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "# For the augmentations\n",
    "import torchvision\n",
    "import random\n",
    "# These two extra for evaluation.\n",
    "import difflib\n",
    "import scipy.spatial\n",
    "# We import glob to find everything that matches a pattern\n",
    "from glob import glob\n",
    "# We install and import SimpleITK for image loading\n",
    "# pip is the package installer for python\n",
    "!pip install SimpleITK\n",
    "import SimpleITK as sitk\n",
    "# To show data, we import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm # progressbar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-taxation",
   "metadata": {},
   "source": [
    "### Data Augmentations\n",
    "##### Add the augmentation so that for a specific type of augmentation the same augmentation is done for both the mask and the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "challenging-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change mask' to 'mask'\n",
    "class transforms(): \n",
    "  def normalize(self, img, x_min, x_max): \n",
    "    max_img = torch.max(img)\n",
    "    min_img = torch.min(img)\n",
    "    nom = (img - min_img) * (x_max - x_min)\n",
    "    denom = max_img - min_img\n",
    "    denom = denom + (denom == 0) \n",
    "    return x_min + nom / denom \n",
    "\n",
    "  def rotate(self, img, mask, degrees): \n",
    "    \"\"\" Function to rotate both the image and mask with a random rotation in the same way.\n",
    "    The degrees paramater has to be passed as a range e.g. (-18, 18).\n",
    "    \"\"\"\n",
    "    angle = torchvision.transforms.RandomRotation.get_params(degrees)\n",
    "    rotated_img = torchvision.transforms.functional.rotate(img, angle)\n",
    "    rotated_mask = torchvision.transforms.functional.rotate(mask, angle)\n",
    "    return rotated_img, rotated_mask\n",
    "\n",
    "  def flip(self, img, mask): # Check if it properly works\n",
    "    flipped_img = torchvision.transforms.functional.hflip(img = img) # change to .vflip for vertical flip\n",
    "    flipped_mask = torchvision.transforms.functional.hflip(img = mask)\n",
    "    return flipped_img, flipped_mask\n",
    "\n",
    "  def scale(self, img, mask, range=0.2): # Check if it properly works\n",
    "    \"\"\"\n",
    "    Function to scale both the image and the mask mask with a random range in the same way\n",
    "    The range parameter is a float that will create a scaled image in the range of 1+- range\n",
    "    has not yet been checked to see if it works\n",
    "    \"\"\"\n",
    "    scale = random.randrange((1-range)*1000, (1+range)*1000)/1000\n",
    "    scaled_img = torchvision.transforms.functional.affine(img=img, angle=0, translate=[0,0], shear=0, scale=scale)\n",
    "    scaled_mask = torchvision.transforms.functional.affine(img=mask, angle=0, translate=[0,0], shear=0, scale=scale)\n",
    "    return scaled_img, scaled_mask\n",
    "\n",
    "  def shear(self, img, mask, degrees): # Check if it properly works.\n",
    "    degree = np.random.randint(-degrees, degrees)\n",
    "    sheared_img = torchvision.transforms.functional.affine(img = img, shear = [degree],\n",
    "                                                         angle = 0, translate = [0,0], scale = 1)\n",
    "    sheared_mask = torchvision.transforms.functional.affine(img = mask, shear = [degree],\n",
    "                                                         angle = 0, translate = [0,0], scale = 1)\n",
    "    return sheared_img, sheared_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-inventory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-indie",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maskDataset(torch.utils.data.Dataset):\n",
    "  # Datasets in Pytorch are classes of the torch.utils.data.Dataset type\n",
    "  # They __must__ have at least three methods:\n",
    "  # - __init__ -> Initialize the dataset, the place where you can pass parameters to it\n",
    "  # - __len__ -> How many samples does your dataset represent?\n",
    "  # - __getitem__ -> A function which takes a parameter i, and returns the ith sample of the dataset\n",
    "\n",
    "  # Note that this DOES NOT perform\n",
    "  # - Batching\n",
    "  # - Asynchronous dataloading (for speed)\n",
    "  # - Merge different datasets on the fly \n",
    "  # - shuffling the data\n",
    "  # More examples like these are solved with \"higher-order\" methods\n",
    "\n",
    "  # but it __might__ do:\n",
    "  # - data augmentation of one sample\n",
    "  # - data normalization of one sample\n",
    "  # - performing on-the-fly data generation\n",
    "  # - hides the nitty-gritty details of dealing with files\n",
    "  def __init__(self, institute, normalize = False, rotate = (False, 0) , flip = False, scale = False, shear = (False, 0)):\n",
    "    self.institute = institute # in this case, we make a dataset per institute\n",
    "    if self.institute == 'Amsterdam':\n",
    "      self.slices = 83\n",
    "      self.datafolder = glob(f'/content/drive/MyDrive/{self.institute}/GE3T/**') #this notation is called an f-string. It \"fills in\" the value of the variable in the string\n",
    "    else:\n",
    "      self.slices = 48\n",
    "      self.datafolder = glob(f'/content/drive/MyDrive/{self.institute}/**')\n",
    "    print(self.datafolder)\n",
    "\n",
    "    # Initializations for data augmentation\n",
    "    self.transforms = transforms()\n",
    "\n",
    "    # I'd suggest passing any extra parameters necessary for the transformation along with the variable as a tuple.\n",
    "    # Then unpack the tuple here and use it later, when applying the augmentation. This way those parameters are not fixed inside the class.\n",
    "    self.normalize = normalize\n",
    "    self.rotate, self.rotation_angle = rotate\n",
    "    self.flip = flip\n",
    "    self.scale = scale\n",
    "    self.shear, self.shear_angle = shear\n",
    "\n",
    "  def __len__(self): # the length is the number of patients scanned at the institute. Every patient is a subfolder in the institute folder\n",
    "    return len(self.datafolder) * self.slices\n",
    "\n",
    "  # This is a helper function to avoid repeating the same SimpleITK function calls to load the images\n",
    "  # It loads the Nifti files, gets a correctly spaced NumPy array, and creates a tensor\n",
    "  def read_image(self, path):\n",
    "    img = sitk.ReadImage(path)\n",
    "    img_as_numpy = sitk.GetArrayFromImage(img).astype('float') # the default type is uint16, which trips up PyTorch so we convert to float\n",
    "    img_as_tensor = torch.from_numpy(img_as_numpy)\n",
    "    return img_as_tensor\n",
    "\n",
    "  def __getitem__(self, i): # return the ith sample of the dataset, note that 0 <= i < len(dataset)\n",
    "    # A slice is considered a sample.\n",
    "\n",
    "    # do some math to check out which slice we want in which folder\n",
    "    folder_index = i // self.slices # Confusion arises. How does this work e.g. when i = 70, since there is no folder 1.\n",
    "    slice_index = i % self.slices\n",
    "    # first we get the paths to the T1 and FLAIR images, and the mask mask\n",
    "    mask_path = f'{self.datafolder[folder_index]}/mask.nii.gz' # Aah so the index is for the array and the value is the actual one in the folder.\n",
    "    t1_path = f'{self.datafolder[folder_index]}/pre/T1.nii.gz'\n",
    "    flair_path = f'{self.datafolder[folder_index]}/pre/FLAIR.nii.gz'\n",
    "\n",
    "    # Actually load the Nifti files and create PyTorch tensors\n",
    "    mask = self.read_image(mask_path)\n",
    "    t1 = self.read_image(t1_path)\n",
    "    flair = self.read_image(flair_path)\n",
    "\n",
    "    # TODO: Data from different institutes are not the same size, crop?\n",
    "    _, x, y = mask.size()\n",
    "    train_tensor = torch.zeros((1, x, y)) # Use only one to avoid error shown.\n",
    "    target_tensor = torch.zeros((1, x, y))\n",
    "\n",
    "    # train_tensor[0, ...] = t1[slice_index, ...]\n",
    "    train_tensor[0, ...] = flair[slice_index, ...] # Suppose only using t1 images to avoid the warning. Put Flair in 0 was in 1.\n",
    "\n",
    "    target_tensor[0, ...] = mask[slice_index, ...]\n",
    "\n",
    "    # Apply normalization\n",
    "    if self.normalize:\n",
    "      train_tensor = self.transforms.normalize(train_tensor, 0, 1)\n",
    "\n",
    "    # Apply data augmentation\n",
    "    if self.rotate:\n",
    "      train_tensor, target_tensor = self.transforms.rotate(train_tensor, target_tensor, self.rotation_angle)\n",
    "    \n",
    "    if self.flip:\n",
    "      train_tensor, target_tensor = self.transforms.flip(train_tensor, target_tensor)\n",
    "    \n",
    "    if self.scale:\n",
    "      train_tensor, target_tensor = self.transforms.scale(train_tensor, target_tensor)\n",
    "    \n",
    "    if self.shear:\n",
    "      train_tensor, target_tensor = self.transforms.shear(train_tensor, target_tensor, self.shear_angle)\n",
    "\n",
    "    # Return the samples as PyTorch tensors\n",
    "    return train_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-acoustic",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure\n",
    "showFig = 'yes'\n",
    "\n",
    "if showFig=='yes':\n",
    "  f, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "\n",
    "  # turn off axis to remove ticks and such\n",
    "  [a.axis('off') for a in ax]\n",
    "\n",
    "  # Here we plot it at the actual subplot we want. We set the colormap to gray (feel free to experiment)\n",
    "  # t1_plot = ax[0].imshow(train[0, :, :], cmap='gray')\n",
    "  flair_plot = ax[1].imshow(train[0, :, :], cmap='gray') # Was one but we only working with flair for now.\n",
    "  mask_plot = ax[2].imshow(target[0, :, :], cmap='gray')\n",
    "\n",
    "  # Add titles and colorbar\n",
    "  # ax[0].set_title('T1')\n",
    "  ax[1].set_title('Image')\n",
    "  ax[2].set_title('Previously provided mask')\n",
    "\n",
    "  # f.colorbar(t1_plot, ax=ax[0], shrink=0.25)\n",
    "  f.colorbar(flair_plot, ax=ax[1], shrink=0.25)\n",
    "  f.colorbar(mask_plot, ax=ax[2], shrink=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-spine",
   "metadata": {},
   "source": [
    "# Model setting & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn # Basic building blocks (containers, different layers ect.)\n",
    "\n",
    "def double_conv(in_channels, out_channels): \n",
    "    return nn.Sequential( # a sequential container, elements are kept in order\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        # 3 is the size of the kernel? Padding is zero padding  \n",
    "        nn.ReLU(inplace=True),\n",
    "        # Activation function ReLU = applies the rectified linear unit function element wise \n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "  # nn.Module is the base class for all neural network modules\n",
    "\n",
    "    def __init__(self, n_class, n_channels):\n",
    "      #Initialization, number of classes, number of channels\n",
    "        super().__init__()\n",
    "        # The U-shape         \n",
    "        self.dconv_down1 = double_conv(n_channels, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2) # a 2x2 kernel \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_loader, lossfunction, device='cuda'):\n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  for batch_idx, (train, target) in enumerate(tqdm(train_loader)):\n",
    "    train, target = train.to(device), target.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train)\n",
    "    loss = lossfunction(target, output)\n",
    "    total_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, test_loader, eval_function, device='cuda'):\n",
    "  model.eval()\n",
    "  total_loss = 0\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (train, target) in enumerate(tqdm(test_loader)):\n",
    "      train, target = train.to(device), target.to(device) \n",
    "      output = model(train)\n",
    "      loss = eval_function(target, output)\n",
    "      total_loss += loss.item()\n",
    "\n",
    "  return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, optimizer, lossfunction, eval_function=None, epochs=25, device='cuda'):\n",
    "  if eval_function is None:\n",
    "    eval_function = lossfunction\n",
    "  train_losses = []\n",
    "  test_losses = []\n",
    "  for epoch in range(epochs):\n",
    "    print('[Epoch %d / %d]' % (epoch + 1, epochs))\n",
    "    train_loss = train_epoch(model, optimizer, train_loader, lossfunction, device)\n",
    "    test_loss = test_epoch(model, test_loader, eval_function, device)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device='cuda'\n",
    "model = UNet(1,1)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-stanford",
   "metadata": {},
   "source": [
    "# Inceasing Dataset with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications on dataset should come bout here, in this and next cell.\n",
    "dataset_all_transforms = maskDataset('Utrecht', rotate = (True, (-18, 18)), shear=(True, 30), scale =True, flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-sharing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-exchange",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
