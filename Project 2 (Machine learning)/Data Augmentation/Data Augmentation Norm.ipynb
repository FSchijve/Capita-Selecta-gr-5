{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "applied-abortion",
   "metadata": {},
   "source": [
    "# Data Augmentation on Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adopted-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dasha's path\n",
    "import os\n",
    "\n",
    "data_path = (r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\TrainingData')\n",
    "elastix_path = os.path.join(r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\elastix-5.0.1-win64\\elastix.exe')\n",
    "transformix_path = os.path.join(r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\elastix-5.0.1-win64\\transformix.exe')\n",
    "\n",
    "patientnr = [102, 107, 108, 109, 115, 116, 117, 119, 120, 125, 127, 128, 129, 133, 135]\n",
    "\n",
    "slice = 86; #slice to visualize \n",
    "nslice = 55; #slice to visualize \n",
    "\n",
    "ip=0; #loop through it!!!!  example of loop below. now for semplicity let's work with only 1 img at the time\n",
    "\n",
    "mask_path=  os.path.join(data_path, 'p{}\\prostaat.mhd'.format(patientnr[ip]))\n",
    "img_path =  os.path.join(data_path, 'p{}\\mr_bffe.mhd'.format(patientnr[ip]))\n",
    "    \n",
    "#for j in patientnr:\n",
    "#    data_path=os.path.join(folder_path,'p{}'.format(j))  \n",
    "#    print(data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hispanic-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giulia's path\n",
    "import os\n",
    "\n",
    "data_path = (r'C:\\Users\\giuli\\Desktop\\Uni Utrecht\\Capita Selecta\\Project\\TrainingData')\n",
    "ELASTIX_PATH = os.path.join(r\"C:\\Users\\giuli\\Elastix\\elastix.exe\")\n",
    "TRANSFORMIX_PATH = os.path.join(r\"C:\\Users\\giuli\\Elastix\\transformix.exe\")\n",
    "\n",
    "slice = 86 # insert the amount of slices we work with                          \n",
    "patientnr = [102, 107, 108, 109, 115, 116, 117, 119, 120, 125, 127, 128, 129, 133, 135]\n",
    "\n",
    "nslice = 55; #slice to visualize \n",
    "\n",
    "ip=0; #loop through it!!!!  example of loop below. now for semplicity let's work with only 1 img at the time\n",
    "\n",
    "mask_path=  os.path.join(data_path, 'p{}\\prostaat.mhd'.format(patientnr[ip]))\n",
    "img_path =  os.path.join(data_path, 'p{}\\mr_bffe.mhd'.format(patientnr[ip]))\n",
    "    \n",
    "#for j in patientnr:\n",
    "#    data_path=os.path.join(folder_path,'p{}'.format(j))  \n",
    "#    print(data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "associate-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening external dataset\n",
    "import os\n",
    "\n",
    "data_path = (r'C:\\Users\\giuli\\Desktop\\Uni Utrecht\\Capita Selecta\\Project\\TrainingData\\Task05_Prostate')\n",
    "\n",
    "#number_list = [00, 01, 02, 04, 06, 07, 10, 13, 14, 16, 17, 18, 20, 21, 24, 25, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47]\n",
    "\n",
    "number_list = [00];\n",
    "slice = 7; #slice to visualize \n",
    "\n",
    "\n",
    "for number in number_list:\n",
    "    mask_path = os.path.join(data_path,f\"imagesTs\\prostate_{number}.nii.gz\"); \n",
    "    img_path  = os.path.join(data_path,f\"imagesTr\\prostate_{number}.nii.gz\");\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intellectual-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in c:\\users\\giuli\\anaconda3\\envs\\capitaselecta\\lib\\site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "# First, we import PyTorch and NumPy\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "# For the augmentations\n",
    "import torchvision\n",
    "import random\n",
    "# These two extra for evaluation.\n",
    "import difflib\n",
    "import scipy.spatial\n",
    "# We import glob to find everything that matches a pattern\n",
    "from glob import glob\n",
    "# We install and import SimpleITK for image loading\n",
    "# pip is the package installer for python\n",
    "!pip install SimpleITK\n",
    "import SimpleITK as sitk\n",
    "# To show data, we import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm # progressbar \n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-taxation",
   "metadata": {},
   "source": [
    "### Data Augmentations\n",
    "##### Add the augmentation so that for a specific type of augmentation the same augmentation is done for both the mask and the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "challenging-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rigid transformation functions\n",
    "\n",
    "class transforms(): \n",
    "  def normalize_img(self, img): \n",
    "    img=img/np.amax(img)\n",
    "    start_x= int(img.shape[0]/2-128)\n",
    "    stop_x = int(img.shape[0]/2+128)\n",
    "    start_y= int(img.shape[1]/2-128)\n",
    "    stop_y = int(img.shape[1]/2+128)\n",
    "    img = img[:,start_x:stop_x,start_y:stop_y]\n",
    "    return img\n",
    "\n",
    "  def normalize_mask(self, mask): \n",
    "    mask[mask>1]=1\n",
    "    start_x= int(mask.shape[0]/2-128)\n",
    "    stop_x = int(mask.shape[0]/2+128)\n",
    "    start_y= int(mask.shape[1]/2-128)\n",
    "    stop_y = int(mask.shape[1]/2+128)\n",
    "    mask  = mask[:,start_x:stop_x,start_y:stop_y]\n",
    "    return mask\n",
    "    \n",
    "    #max_img = torch.max(img)\n",
    "    #min_img = torch.min(img)\n",
    "    #nom = (img - min_img) * (x_max - x_min)\n",
    "    #denom = max_img - min_img\n",
    "    #denom = denom + (denom == 0) \n",
    "    #return x_min + nom / denom \n",
    "\n",
    "  def rotate(self, img, mask, degrees): \n",
    "    \"\"\" Function to rotate both the image and mask with a random rotation in the same way.\n",
    "    The degrees paramater has to be passed as a range e.g. (-18, 18).\n",
    "    \"\"\"\n",
    "    angle = torchvision.transforms.RandomRotation.get_params(degrees)\n",
    "    rotated_img = torchvision.transforms.functional.rotate(img, angle)\n",
    "    rotated_mask = torchvision.transforms.functional.rotate(mask, angle)\n",
    "    return rotated_img, rotated_mask\n",
    "\n",
    "  def flip(self, img, mask): # Check if it properly works\n",
    "    flipped_img = torchvision.transforms.functional.hflip(img = img) # change to .vflip for vertical flip\n",
    "    flipped_mask = torchvision.transforms.functional.hflip(img = mask)\n",
    "    return flipped_img, flipped_mask\n",
    "\n",
    "  def scale(self, img, mask, range=0.2): # Check if it properly works\n",
    "    \"\"\"\n",
    "    Function to scale both the image and the mask mask with a random range in the same way\n",
    "    The range parameter is a float that will create a scaled image in the range of 1+- range\n",
    "    has not yet been checked to see if it works\n",
    "    \"\"\"\n",
    "    scale = random.randrange((1-range)*1000, (1+range)*1000)/1000\n",
    "    scaled_img = torchvision.transforms.functional.affine(img=img, angle=0, translate=[0,0], shear=0, scale=scale)\n",
    "    scaled_mask = torchvision.transforms.functional.affine(img=mask, angle=0, translate=[0,0], shear=0, scale=scale)\n",
    "    return scaled_img, scaled_mask\n",
    "\n",
    "  def shear(self, img, mask, degrees): # Check if it properly works.\n",
    "    degree = np.random.randint(-degrees, degrees)\n",
    "    sheared_img = torchvision.transforms.functional.affine(img = img, shear = [degree],\n",
    "                                                         angle = 0, translate = [0,0], scale = 1)\n",
    "    sheared_mask = torchvision.transforms.functional.affine(img = mask, shear = [degree],\n",
    "                                                         angle = 0, translate = [0,0], scale = 1)\n",
    "    return sheared_img, sheared_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mechanical-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-rigid transformation fuctions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adapted-prophet",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-21-f039775b8121>, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-f039775b8121>\"\u001b[1;36m, line \u001b[1;32m41\u001b[0m\n\u001b[1;33m    return len(self.datafolder) * self.slices\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class maskDataset(torch.utils.data.Dataset):\n",
    "  # Datasets in Pytorch are classes of the torch.utils.data.Dataset type\n",
    "  # They __must__ have at least three methods:\n",
    "  # - __init__ -> Initialize the dataset, the place where you can pass parameters to it\n",
    "  # - __len__ -> How many samples does your dataset represent?\n",
    "  # - __getitem__ -> A function which takes a parameter i, and returns the ith sample of the dataset\n",
    "\n",
    "  # Note that this DOES NOT perform\n",
    "  # - Batching\n",
    "  # - Asynchronous dataloading (for speed)\n",
    "  # - Merge different datasets on the fly \n",
    "  # - shuffling the data\n",
    "  # More examples like these are solved with \"higher-order\" methods\n",
    "\n",
    "  # but it __might__ do:\n",
    "  # - data augmentation of one sample\n",
    "  # - data normalization of one sample\n",
    "  # - performing on-the-fly data generation\n",
    "  # - hides the nitty-gritty details of dealing with files\n",
    "    \n",
    "  def __init__(self, normalize_img = False, normalize_mask = False, rotate = (False, 0) , flip = False, scale = False, shear = (False, 0)):\n",
    "    \n",
    "    self.slices = slice \n",
    "    self.datafolder = glob(data_path)\n",
    "    print(\"self.datafolder is: \", self.datafolder)\n",
    "    #print(\"patientnr\", patientnr)\n",
    "\n",
    "    # Initializations for data augmentation\n",
    "    self.transforms = transforms()\n",
    "\n",
    "    # I'd suggest passing any extra parameters necessary for the transformation along with the variable as a tuple.\n",
    "    # Then unpack the tuple here and use it later, when applying the augmentation. This way those parameters are not fixed inside the class.\n",
    "    self.normalize_img  = normalize_img\n",
    "    self.normalize_mask = normalize_mask\n",
    "    self.rotate, self.rotation_angle = rotate\n",
    "    self.flip = flip\n",
    "    self.scale = scale\n",
    "    self.shear, self.shear_angle = shear\n",
    "\n",
    "  def __len__(self): folder\n",
    "    return len(self.datafolder) * self.slices\n",
    "\n",
    "  # This is a helper function to avoid repeating the same SimpleITK function calls to load the images\n",
    "  # It loads the Nifti files, gets a correctly spaced NumPy array, and creates a tensor\n",
    "  def read_image(self, path):\n",
    "    img = sitk.ReadImage(path)\n",
    "    img_as_numpy = sitk.GetArrayFromImage(img).astype('float') # the default type is uint16, which trips up PyTorch so we convert to float\n",
    "    img_as_tensor = torch.from_numpy(img_as_numpy)\n",
    "    return img_as_tensor\n",
    "\n",
    "  def __getitem__(self, i): # return the ith sample of the dataset, note that 0 <= i < len(dataset)\n",
    "    # A slice is considered a sample.\n",
    "         \n",
    "    # Actually load the Nifti files and create PyTorch tensors\n",
    "    #nib.load().get_data()\n",
    "    mask = self.read_image(mask_path)\n",
    "    img  = self.read_image(img_path)\n",
    "  \n",
    "    _, x, y = mask.size()\n",
    "    train_tensor = torch.zeros((1, x, y)) # Use only one to avoid error shown.\n",
    "    target_tensor = torch.zeros((1, x, y))\n",
    "    \n",
    "    slice_index = i % self.slices\n",
    "    train_tensor[0, ...] = img[slice_index, ...]\n",
    "    target_tensor[0, ...]= mask[slice_index, ...]\n",
    "\n",
    "    # Apply normalization\n",
    "    if self.normalize_img:\n",
    "      train_tensor = self.transforms.normalize_img(train_tensor)\n",
    "    \n",
    "    if self.normalize_mask:\n",
    "      train_tensor = self.transforms.normalize_mask(train_tensor)\n",
    "    \n",
    "    # Apply data augmentation\n",
    "    if self.rotate:\n",
    "      train_tensor, target_tensor = self.transforms.rotate(train_tensor, target_tensor, self.rotation_angle)\n",
    "    \n",
    "    if self.flip:\n",
    "      train_tensor, target_tensor = self.transforms.flip(train_tensor, target_tensor)\n",
    "    \n",
    "    if self.scale:\n",
    "      train_tensor, target_tensor = self.transforms.scale(train_tensor, target_tensor)\n",
    "    \n",
    "    if self.shear:\n",
    "      train_tensor, target_tensor = self.transforms.shear(train_tensor, target_tensor, self.shear_angle)\n",
    "\n",
    "    # Return the samples as PyTorch tensors\n",
    "    return train_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load data\n",
    "\n",
    "dataset = maskDataset() # Note this dataset is now already normalized.\n",
    "len(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at what the data looks like\n",
    "train, target = dataset[slice]\n",
    "train.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-acoustic",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-simon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the figure\n",
    "showFig = 'yes'\n",
    "\n",
    "if showFig=='yes':\n",
    "  f, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "\n",
    "  # turn off axis to remove ticks and such\n",
    "  [a.axis('off') for a in ax]\n",
    "\n",
    "  # Here we plot it at the actual subplot we want. We set the colormap to gray (feel free to experiment)\n",
    "  img_plot = ax[0].imshow(train[0, :, :], cmap='gray') # Was one but we only working with flair for now.\n",
    "  mask_plot = ax[1].imshow(target[0, :, :], cmap='gray')\n",
    "\n",
    "  # Add titles and colorbar\n",
    "  ax[0].set_title('Image')\n",
    "  ax[1].set_title('Previously provided mask')\n",
    "\n",
    "  f.colorbar(img_plot, ax=ax[0], shrink=0.25)\n",
    "  f.colorbar(mask_plot, ax=ax[1], shrink=0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
