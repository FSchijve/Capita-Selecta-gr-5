{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "applied-abortion",
   "metadata": {},
   "source": [
    "# Data Augmentation on Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adopted-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dasha's path\n",
    "import os\n",
    "\n",
    "data_path = (r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\TrainingData')\n",
    "elastix_path = os.path.join(r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\elastix-5.0.1-win64\\elastix.exe')\n",
    "transformix_path = os.path.join(r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\elastix-5.0.1-win64\\transformix.exe')\n",
    "\n",
    "patientnr = [102, 107, 108, 109, 115, 116, 117, 119, 120, 125, 127, 128, 129, 133, 135]\n",
    "\n",
    "slice = 86; #slice to visualize \n",
    "nslice = 55; #slice to visualize \n",
    "\n",
    "ip=0; #loop through it!!!!  example of loop below. now for semplicity let's work with only 1 img at the time\n",
    "\n",
    "mask_path=  os.path.join(data_path, 'p{}\\prostaat.mhd'.format(patientnr[ip]))\n",
    "img_path =  os.path.join(data_path, 'p{}\\mr_bffe.mhd'.format(patientnr[ip]))\n",
    "    \n",
    "#for j in patientnr:\n",
    "#    data_path=os.path.join(folder_path,'p{}'.format(j))  \n",
    "#    print(data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hispanic-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giulia's path\n",
    "import os\n",
    "\n",
    "data_path = (r'C:\\Users\\giuli\\Desktop\\Uni Utrecht\\Capita Selecta\\Project\\TrainingData')\n",
    "ELASTIX_PATH = os.path.join(r\"C:\\Users\\giuli\\Elastix\\elastix.exe\")\n",
    "TRANSFORMIX_PATH = os.path.join(r\"C:\\Users\\giuli\\Elastix\\transformix.exe\")\n",
    "\n",
    "slice = 86 # insert the amount of slices we work with                          \n",
    "patientnr = [102, 107, 108, 109, 115, 116, 117, 119, 120, 125, 127, 128, 129, 133, 135]\n",
    "\n",
    "nslice = 55; #slice to visualize \n",
    "\n",
    "ip=0; #loop through it!!!!  example of loop below. now for semplicity let's work with only 1 img at the time\n",
    "\n",
    "mask_path=  os.path.join(data_path, 'p{}\\prostaat.mhd'.format(patientnr[ip]))\n",
    "img_path =  os.path.join(data_path, 'p{}\\mr_bffe.mhd'.format(patientnr[ip]))\n",
    "    \n",
    "#for j in patientnr:\n",
    "#    data_path=os.path.join(folder_path,'p{}'.format(j))  \n",
    "#    print(data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intellectual-letter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in c:\\users\\darja\\anaconda3\\envs\\part2_8md20\\lib\\site-packages (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "# First, we import PyTorch and NumPy\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "# For the augmentations\n",
    "import torchvision\n",
    "import random\n",
    "# These two extra for evaluation.\n",
    "import difflib\n",
    "import scipy.spatial\n",
    "# We import glob to find everything that matches a pattern\n",
    "from glob import glob\n",
    "# We install and import SimpleITK for image loading\n",
    "# pip is the package installer for python\n",
    "!pip install SimpleITK\n",
    "import SimpleITK as sitk\n",
    "# To show data, we import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm # progressbar \n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-taxation",
   "metadata": {},
   "source": [
    "### Data Augmentations\n",
    "##### Add the augmentation so that for a specific type of augmentation the same augmentation is done for both the mask and the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "challenging-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rigid transformation functions\n",
    "\n",
    "class transforms(): \n",
    "  def normalize_img(self, img): \n",
    "    img=img/np.amax(img)\n",
    "    start_x= int(img.shape[0]/2-128)\n",
    "    stop_x = int(img.shape[0]/2+128)\n",
    "    start_y= int(img.shape[1]/2-128)\n",
    "    stop_y = int(img.shape[1]/2+128)\n",
    "    img = img[:,start_x:stop_x,start_y:stop_y]\n",
    "    return img\n",
    "\n",
    "  def normalize_mask(self, mask): \n",
    "    mask[mask>1]=1\n",
    "    start_x= int(mask.shape[0]/2-128)\n",
    "    stop_x = int(mask.shape[0]/2+128)\n",
    "    start_y= int(mask.shape[1]/2-128)\n",
    "    stop_y = int(mask.shape[1]/2+128)\n",
    "    mask  = mask[:,start_x:stop_x,start_y:stop_y]\n",
    "    return mask\n",
    "    \n",
    "    #max_img = torch.max(img)\n",
    "    #min_img = torch.min(img)\n",
    "    #nom = (img - min_img) * (x_max - x_min)\n",
    "    #denom = max_img - min_img\n",
    "    #denom = denom + (denom == 0) \n",
    "    #return x_min + nom / denom \n",
    "\n",
    "  def rotate(self, img, mask, degrees): \n",
    "    \"\"\" Function to rotate both the image and mask with a random rotation in the same way.\n",
    "    The degrees paramater has to be passed as a range e.g. (-18, 18).\n",
    "    \"\"\"\n",
    "    angle = torchvision.transforms.RandomRotation.get_params(degrees)\n",
    "    rotated_img = torchvision.transforms.functional.rotate(img, angle)\n",
    "    rotated_mask = torchvision.transforms.functional.rotate(mask, angle)\n",
    "    return rotated_img, rotated_mask\n",
    "\n",
    "  def flip(self, img, mask): # Check if it properly works\n",
    "    flipped_img = torchvision.transforms.functional.hflip(img = img) # change to .vflip for vertical flip\n",
    "    flipped_mask = torchvision.transforms.functional.hflip(img = mask)\n",
    "    return flipped_img, flipped_mask\n",
    "\n",
    "  def scale(self, img, mask, range=0.2): # Check if it properly works\n",
    "    \"\"\"\n",
    "    Function to scale both the image and the mask mask with a random range in the same way\n",
    "    The range parameter is a float that will create a scaled image in the range of 1+- range\n",
    "    has not yet been checked to see if it works\n",
    "    \"\"\"\n",
    "    scale = random.randrange((1-range)*1000, (1+range)*1000)/1000\n",
    "    scaled_img = torchvision.transforms.functional.affine(img=img, angle=0, translate=[0,0], shear=0, scale=scale)\n",
    "    scaled_mask = torchvision.transforms.functional.affine(img=mask, angle=0, translate=[0,0], shear=0, scale=scale)\n",
    "    return scaled_img, scaled_mask\n",
    "\n",
    "  def shear(self, img, mask, degrees): # Check if it properly works.\n",
    "    degree = np.random.randint(-degrees, degrees)\n",
    "    sheared_img = torchvision.transforms.functional.affine(img = img, shear = [degree],\n",
    "                                                         angle = 0, translate = [0,0], scale = 1)\n",
    "    sheared_mask = torchvision.transforms.functional.affine(img = mask, shear = [degree],\n",
    "                                                         angle = 0, translate = [0,0], scale = 1)\n",
    "    return sheared_img, sheared_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mechanical-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-rigid transformation fuctions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adapted-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class maskDataset(torch.utils.data.Dataset):\n",
    "  # Datasets in Pytorch are classes of the torch.utils.data.Dataset type\n",
    "  # They __must__ have at least three methods:\n",
    "  # - __init__ -> Initialize the dataset, the place where you can pass parameters to it\n",
    "  # - __len__ -> How many samples does your dataset represent?\n",
    "  # - __getitem__ -> A function which takes a parameter i, and returns the ith sample of the dataset\n",
    "\n",
    "  # Note that this DOES NOT perform\n",
    "  # - Batching\n",
    "  # - Asynchronous dataloading (for speed)\n",
    "  # - Merge different datasets on the fly \n",
    "  # - shuffling the data\n",
    "  # More examples like these are solved with \"higher-order\" methods\n",
    "\n",
    "  # but it __might__ do:\n",
    "  # - data augmentation of one sample\n",
    "  # - data normalization of one sample\n",
    "  # - performing on-the-fly data generation\n",
    "  # - hides the nitty-gritty details of dealing with files\n",
    "    \n",
    "  def __init__(self, normalize_img = False, normalize_mask = False, rotate = (False, 0) , flip = False, scale = False, shear = (False, 0)):\n",
    "    self.x = int(mask.shape[0])\n",
    "    self.y = int(mask.shape[1])\n",
    "    self.slices = slice \n",
    "    self.datafolder = glob(data_path)\n",
    "    # print(\"self.datafolder is: \", self.datafolder)\n",
    "    #print(\"patientnr\", patientnr)\n",
    "\n",
    "    # Initializations for data augmentation\n",
    "    self.transforms = transforms()\n",
    "\n",
    "    # I'd suggest passing any extra parameters necessary for the transformation along with the variable as a tuple.\n",
    "    # Then unpack the tuple here and use it later, when applying the augmentation. This way those parameters are not fixed inside the class.\n",
    "    self.normalize_img  = normalize_img\n",
    "    self.normalize_mask = normalize_mask\n",
    "    self.rotate, self.rotation_angle = rotate\n",
    "    self.flip = flip\n",
    "    self.scale = scale\n",
    "    self.shear, self.shear_angle = shear\n",
    "\n",
    "  def __len__(self): #folder\n",
    "     return 1\n",
    "\n",
    "  # This is a helper function to avoid repeating the same SimpleITK function calls to load the images\n",
    "  # It loads the Nifti files, gets a correctly spaced NumPy array, and creates a tensor\n",
    "  def read_image(self, path):\n",
    "    img = sitk.ReadImage(path)\n",
    "    img_as_numpy = sitk.GetArrayFromImage(img).astype('float') # the default type is uint16, which trips up PyTorch so we convert to float\n",
    "    img_as_tensor = torch.from_numpy(img_as_numpy)\n",
    "    return img_as_tensor\n",
    "\n",
    "  def __getitem__(self, i): # return the ith sample of the dataset, note that 0 <= i < len(dataset)\n",
    "    # A slice is considered a sample.\n",
    "  \n",
    "\n",
    "    _, x, y = mask.size()\n",
    "    train_tensor = torch.zeros((1, x, y)) # Use only one to avoid error shown.\n",
    "    target_tensor = torch.zeros((1, x, y))\n",
    "    \n",
    "    #slice_index = i % self.slices\n",
    "    train_tensor[0, ...] = img[slice, ...]\n",
    "    target_tensor[0, ...]= mask[slice, ...]\n",
    "\n",
    "    # Apply normalization\n",
    "    if self.normalize_img:\n",
    "      train_tensor = self.transforms.normalize_img(train_tensor)\n",
    "    \n",
    "    if self.normalize_mask:\n",
    "      train_tensor = self.transforms.normalize_mask(train_tensor)\n",
    "    \n",
    "    # Apply data augmentation\n",
    "    if self.rotate:\n",
    "      train_tensor, target_tensor = self.transforms.rotate(train_tensor, target_tensor, self.rotation_angle)\n",
    "    \n",
    "    if self.flip:\n",
    "      train_tensor, target_tensor = self.transforms.flip(train_tensor, target_tensor)\n",
    "    \n",
    "    if self.scale:\n",
    "      train_tensor, target_tensor = self.transforms.scale(train_tensor, target_tensor)\n",
    "    \n",
    "    if self.shear:\n",
    "      train_tensor, target_tensor = self.transforms.shear(train_tensor, target_tensor, self.shear_angle)\n",
    "\n",
    "    # Return the samples as PyTorch tensors\n",
    "    return train_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-fleet",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "#### Patient+ slice loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adapted-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-3f9e1b82c9cb>:16: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  mask = np.rot90(nib.load(mask_path).get_data()[:,:,slice])\n",
      "<ipython-input-7-3f9e1b82c9cb>:17: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  img = np.rot90(nib.load(img_path).get_data()[:,:,slice,0])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-3f9e1b82c9cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m#Take a look at what the data looks like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ffa1c20fade3>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mtrain_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Use only one to avoid error shown.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mtarget_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# Opening external dataset\n",
    "data_path = (r'C:\\Users\\darja\\Documents\\TuE\\elastix-5.0.1-win64\\TrainingData\\Task05_Prostate')\n",
    "\n",
    "number_list = [0, 1, 2, 4, 6, 7, 10, 13, 14, 16, 17, 18, 20, 21, 24, 25, 28, 29, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47]\n",
    "\n",
    "# Loop the slices    \n",
    "slice_list = [15, 20, 24, 15, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 19, 11, 15, 20, 20, 15, 20, 15, 20, 15, 20, 18, 22, 20, 20, 20, 20]\n",
    "i = -1\n",
    "\n",
    "# loop the patients\n",
    "for number in number_list:\n",
    "    i = i + 1\n",
    "    mask_path = os.path.join(data_path,f\"labelsTr\\prostate_{number}.nii.gz\"); \n",
    "    img_path  = os.path.join(data_path,f\"imagesTr\\prostate_{number}.nii.gz\")\n",
    "    for slice in range(slice_list[i]):\n",
    "        mask = np.rot90(nib.load(mask_path).get_data()[:,:,slice]) \n",
    "        img = np.rot90(nib.load(img_path).get_data()[:,:,slice,0]) \n",
    "        dataset = maskDataset()  \n",
    "        print (i)\n",
    "        \n",
    "        #Take a look at what the data looks like\n",
    "        train, target = dataset[1]\n",
    "        train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at what the data looks like\n",
    "train, target = dataset[slice]\n",
    "train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complimentary-imaging",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_as_numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3df713e7ab5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_as_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'img_as_numpy' is not defined"
     ]
    }
   ],
   "source": [
    "print(img_as_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unexpected-giving",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-d53ea7098c31>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-d53ea7098c31>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    results_patient0 = [rotated_img, rotated_mask;\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Output array\n",
    "results_patient0 = [rotated_img, rotated_mask; \n",
    "                    flipped_img, flipped_mask; \n",
    "                    scaled_img, scaled_mask; \n",
    "                    sheared_img, sheared_mask;]\n",
    "# print(img_as_numpy)\n",
    "print(results_patient0)\n",
    "\n",
    "\n",
    "# loop it so output of all the patients would come out as a huuuge array\n",
    "# results_all = \n",
    "# print(results_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-acoustic",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-simon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the figure\n",
    "showFig = 'yes'\n",
    "\n",
    "if showFig=='yes':\n",
    "  f, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "\n",
    "  # turn off axis to remove ticks and such\n",
    "  [a.axis('off') for a in ax]\n",
    "\n",
    "  # Here we plot it at the actual subplot we want. We set the colormap to gray (feel free to experiment)\n",
    "  img_plot = ax[0].imshow(train[0, :, :], cmap='gray') # Was one but we only working with flair for now.\n",
    "  mask_plot = ax[1].imshow(target[0, :, :], cmap='gray')\n",
    "\n",
    "  # Add titles and colorbar\n",
    "  ax[0].set_title('Image')\n",
    "  ax[1].set_title('Previously provided mask')\n",
    "\n",
    "  f.colorbar(img_plot, ax=ax[0], shrink=0.25)\n",
    "  f.colorbar(mask_plot, ax=ax[1], shrink=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-processing",
   "metadata": {},
   "source": [
    "## Increasing dataset with augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications on dataset should come bout here, in this and next cell.\n",
    "dataset_all_transforms = WMHDataset('Utrecht', rotate = (True, (-18, 18)), shear=(True, 30), scale =True, flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-incident",
   "metadata": {},
   "source": [
    "### Take a look at the augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-football",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
